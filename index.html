<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Practical Machine Learning Assignment by rpaydo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Practical Machine Learning Assignment</h1>
      <h2 class="project-tagline">Assignment for Practical Machine Learning course</h2>
      <a href="https://github.com/rpaydo/PracticalMachineLearning" class="btn">View on GitHub</a>
      <a href="https://github.com/rpaydo/PracticalMachineLearning/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/rpaydo/PracticalMachineLearning/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p>

</p>

<p></p>



<p>
</p>







code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>

<div>




<div id="machine-learning-assignment">
<h2>
<a id="machine-learning-assignment" class="anchor" href="#machine-learning-assignment" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Machine Learning Assignment</h2>
<div id="assignment-objective">
<h3>
<a id="assignment-objective" class="anchor" href="#assignment-objective" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Assignment Objective</h3>
<p>The purpose of this assignment is to develop a model that will predict how well a person can<br>perform a bar bell lift using data from multiple accelerometers. The data used to produce<br>the model comes from the Weight Lifting Exercise dataset from the Human Activity Recognition<br>project. The data was collected from a set of accelerometers connected to the arm, forearm,<br>belt, and dumbbell while five participants performed one set of 10 unilateral dumbbell<br>biceps curls.</p>
</div>

<div id="analysis-steps">
<h3>
<a id="analysis-steps" class="anchor" href="#analysis-steps" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Analysis Steps</h3>
<p>The first section of code loads the caret package that will be used for model development and<br>loads two datasets from the website: a set complete with exercise classifications and a set<br>that has not been classified and that will be used for model verification.</p>
<pre><code>library(caret)</code></pre>
<pre><code>## Warning: package 'caret' was built under R version 3.2.1</code></pre>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2</code></pre>
<pre><code>## Warning: package 'ggplot2' was built under R version 3.2.2</code></pre>
<pre><code>alldata=read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
quiz=read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))</code></pre>
<p>Performing a few data summaries reveals that many of the variables in the dataset have a<br>large number of readings that are either blank or NA. In addition, there are a few variables<br>that serve as row markers or timestamps. Prior to model development, we will eliminate these<br>variables from the dataset. This will reduce the total number of variables from 160 to 55 and<br>will speed up the model development steps.</p>
<pre><code>mydata &lt;- alldata[,colSums(is.na(alldata))&lt;19000]
mydata &lt;- mydata[,colSums(mydata=="")&lt;19000]
mydata=mydata[,6:60]</code></pre>
<p>Now that the data has been cleaned, we will divide the data into a training set to build the<br>model and a testing set to cross-validate the model. We will use random subsetting without<br>replacement. For reproducibility purposes, we will set a seed in R prior to making the split.</p>
<pre><code>set.seed(123)
inTrain=createDataPartition(y=mydata$classe,p=0.75,list=FALSE)
training=mydata[inTrain,]
testing=mydata[-inTrain,]</code></pre>
<p>In the next step, we will use the training set to build a model. for this exercise, we will<br>use a random forest model. The random forest technique builds multiple decision trees with<br>the data and uses the multiple trees to vote for the correct class. The model can take<br>longer to generate but is very accurate. For this model, the output variable is classe. We<br>will use all remaining variables in the dataset as predictors. Again, for reproducibility<br>purposes, we will set a seed in R so that the exact random forest can be recreated.</p>
<pre><code>set.seed(516)
modFitrf=train(classe~.,data=training,method="rf")</code></pre>
<pre><code>## Loading required package: randomForest</code></pre>
<pre><code>## Warning: package 'randomForest' was built under R version 3.2.1</code></pre>
<pre><code>## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<p>Now that the model has been built, we will validate the accuracy of the model by using it<br>to predict classe values in the testing set that we created with the earlier split. Since<br>the testing set already contains values for classe, we can compare our predicted values to<br>the actual values from the dataset to see how accurate the model is. We will generate a<br>confusion matrix that will show how often the model agrees with the actual values (accuracy).<br>We will also be able to see various statistics for each of the five potential outcomes,<br>including sensitivity, specificity.</p>
<pre><code>pred=predict(modFitrf,testing)
confusionMatrix(pred,testing$classe)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1395    1    0    0    0
##          B    0  948    1    0    0
##          C    0    0  854    3    0
##          D    0    0    0  801    0
##          E    0    0    0    0  901
## 
## Overall Statistics
##                                           
##                Accuracy : 0.999           
##                  95% CI : (0.9976, 0.9997)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9987          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9989   0.9988   0.9963   1.0000
## Specificity            0.9997   0.9997   0.9993   1.0000   1.0000
## Pos Pred Value         0.9993   0.9989   0.9965   1.0000   1.0000
## Neg Pred Value         1.0000   0.9997   0.9998   0.9993   1.0000
## Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837
## Detection Rate         0.2845   0.1933   0.1741   0.1633   0.1837
## Detection Prevalence   0.2847   0.1935   0.1748   0.1633   0.1837
## Balanced Accuracy      0.9999   0.9993   0.9990   0.9981   1.0000</code></pre>
<p>Since the testing set was not utilized to build the model, the modelâ€™s performance on the<br>test set will give a good idea of what its out of sample error would be. Based on the<br>confusion matrix, the model had an accuracy of 99.9% on the testing set and<br>miscategorized only 5 samples out of 4904. The No information rate shows how accurate we<br>would expect to be in making predictions with no model at all. The random forest model<br>improves that accuracy by 71%, which is statistically significant based on the p-value. The<br>confidence interval on the accuracy is also very small due to the large number of samples in<br>the testing set. The individual sensitivities and specificities for each category are also extremely high. Overall, the model performed extremely well.</p>
<p>Next, we can look at which variables in the model were the most important for the model. The<br>most important variable was num window followed by Toll belt. The rest of the variables,<br>ranked by importance, can be seen in the plot below:</p>
<p><img title alt width="672"></p>
<p>Now that we have verified the performance of the model through cross-validation and gained<br>some insight into which variables had the biggest impact on the model, the final step is to<br>use the model to predict categories for the 20 samples for the quiz. Unlike the validation<br>on the testing set, we do not already know the categories for the quiz samples. The<br>predictions for these samples are as follows:</p>
<pre><code>predquiz=predict(modFitrf,quiz)
predquiz</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
<p>These answers were submitted through the Coursera assessment and were all correct.</p>
</div>

<div id="conclusion">
<h3>
<a id="conclusion" class="anchor" href="#conclusion" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Conclusion</h3>
<p>The model was validated twice: once on the testing set and once on the quiz set and was<br>extremely accurate in both. Based on these results, it is fair to say that the sensors<br>in the accelerometers can be used to accurately say whether a dumbbell lift is being performed<br>correctly. A customer can have confidence that he is performing the exercise correctly<br>as long as his sensors do not indicate otherwise.</p>
</div>

<p></p>
</div>

<p></p>
</div>







<p>
</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/rpaydo/PracticalMachineLearning">Practical Machine Learning Assignment</a> is maintained by <a href="https://github.com/rpaydo">rpaydo</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
